\documentclass[]{article}

\usepackage{datetime}

\newcommand{\spec}[1]{\textit{#1}\par\noindent}

% Uncomment the following to hide spec:
% \renewcommand{\spec}[1]{}

\newdate{date}{9}{12}{2016}
\date{\displaydate{date}}

\title{WACC Compiler Report}
\author{
	Anantachok Duangsarot \\
	\and
	James Knight \\
	\and
	Jaspreet Randhawa \\
	\and
	Max Smith \\
}

\begin{document}

\maketitle

\section{The Product}
\spec{An analysis and critical evaluation of the quality of the WACC compiler you have built. You should consider both whether it meets the functional specification and whether you judge that it forms a sound basis for future development. You may wish to address performance issues.}
Firstly, the frontend of our compiler turned out very well. The lexer and parser represent the specification perfectly, with the ANTLR framework performing the bulk of the work for the lexical and syntactic analysis. The semantic analysis was more challenging, with ANTLR only providing a groundwork through the visitor pattern. In the end though, we successfully managed to meet the specification, passing all of the example tests provided. This frontend gave us a strong building block for starting the backend, as we knew that we wouldn't have to go back to fix it and all of our efforts could be focused on the backend.

The backend was a much more challenging task. Some early decisions of the backend's design made things more difficult as time went on. Overall, we managed to get it to a point in which it passed most of the specification, however there are still some things that the compiler fails to do, for example treating strings as mutable char arrays.

We made a decision to have the compiler generate functional code over optimised code so that we had more time to complete the specification, however this results in some ugly code generated. For example, instead of moving the stack pointer by the number of variables needed every time we enter a new scope, we instead move the stack pointer every time a variable is declared, vastly increasing the number of SUB commands in a program with many variables.

Also, the compiler doesn't check whether a string has already been used previously in the program. This means, if a program uses the same string multiple times, it will appear at the head of the file multiple times. This can make the code difficult to read.

The difficulty of future development is mixed. Whilst we think it's easy to make certain improvements, such as extending the language specification in many ways (some of which we have done in our extension), other improvments such as some compiler optimisations are more difficult. The way the backend is designed, instructions know very little about the program state other than their own children in the tree. This makes it hard to make changes that rely on knowing things like the number of registers that are going to be used or when variables are used, which makes it hard to make many of the optimisations.

\section{The Project Management}
\spec{An analysis of the organisation of your group and your use of project management tools (such as Git). You should describe how your group was structured, how you coordinated your work and detail any tools that helped/hindered your progress. You should also discuss what went well and what you would do differently if you were to do the lab again.}
We organised our project using Git. By using the Git branching tools, we managed to easily distinguish between functioning and non-functioning code, and avoid merge conflicts. Firstly, we made sure to reserve the master branch for functioning code. By making sure that only code that compiles and runs successfully is on the master branch, we always knew which version we had to run large-scale testing on.

Non-tested code was put on the development branch. We tried to make sure that the code here would always compile, but we were less strict about that on this branch. Once we were confident that the code on development worked properly, we would merge it into master. Each individual group member would develop on their own branch, then merge onto the development branch once they were done. This allowed us to avoid merge conflicts, as there was never more than one person working on the same branch at the same time. 

We worked together to build the general structure of the frontend and backend so that we all knew how the program would function, then divided tasks between each of us. Whilst a lot of the code was written individually, we also did some pair programming as we found that having a second pair of eyes was useful.

We wrote a test suite in ruby, designed to mimic the test suite on LabTS. This meant we could test code quicker than using LabTS and allowed us to do testing without having to merge bad code onto the master branch. This turned out to be incredibly useful, and had added benefits such as being able to test only specific categories of tests to save time. This improved our productivity greatly as their was much less downtime from waiting for LabTS to test code.

However, there are a few things that we would change if we were to do the lab again. Whilst we are very happy with the frontend, we think the backend could do with some improvement. Firstly, we would start on the backend earlier, as we were pressed for time which stopped us from doing as much as we had wanted. Also, we would spend some more time planning out the design of the backend and weighing out the pros and cons of different design patterns. The way we ended up doing it, we stumbled upon a lot of issues which could be fixed by changing the design, but at that point we were too far in to rewrite the program completely.

\section{The Design Choices}
\spec{An analysis of the design choices that you made during the WACC lab. You should discuss the design patterns you used when designing your code and why you chose to use them.}
We used a variety of different patterns whilst designing the WACC lab. Firstly, we use a listener pattern for the error listener. This is an object that subscribes to the syntax parser. Whenever the parser throws an error, the error listener is notified, so it can handle that error by printing a useful error message for the user.

Next, there is the most important one - the visitor pattern. The ANTLR tool that we used generates a default visitor pattern for traversing the Abstract Syntax Tree (AST). As each node of the tree contains different tokens, each node needs to be a different class. So that we can access the contents of these nodes and perform different operations on them, we need to use a visitor pattern, which provides a separate visit function for each of these different classes. We use this in our frontend, where we perform semantic analysis.

We use a second visitor pattern in the backend, where we traverse the AST and generate the corresponding instructions. We do this by building an instruction tree - each node of the AST has it's own instruction class which may take a number of child instructions. Each instruction has a toAssembly method which takes a PrintStream and outputs the assembly for its instruction, calling its children's toAssembly methods in the process. By building the instruction tree as we walk the AST, we allow each node to know about the program state and instructions of its children. Then, after the whole tree is generated, we can call the toAssembly method of the head of the tree to print out the whole program.

Control flow instructions use branching to navigate the program. This requires us to generate labels to denote where to branch to, but these labels need to be unique so that the assembly is valid. We do this using a LabelMaker class which implements the singleton pattern. This labelmaker contains a map of instructions to label names, allowing it to generate a unique label name for that instruction, and then retrieve that label name later. By having it as a singleton class, there can only ever be one LabelMaker generated, meaning there is only a single map. This stops any errors where two instructions generate two different LabelMakers, then end up generating the same label. As a side effect, this allows for static access to the LabelMaker, meaning it does not have to be passed to the instructions.

\section{Beyond the Specification}
\spec{An evaluation of your extensions to your WACC compiler. You should describe all of the language extensions, optimisations or other aspects that you have added to your compiler, including how these features can be accessed or viewed. You should also briefly discuss what future extensions you would like to add to your WACC compiler if you had more time.}
...
\subsection{Max}



\subsection{Anant}
\subsubsection{break and continue}
\subparagraph*{The compiler was extented to allow break and continue statement in if, while and for loops. In the Frontend, we check that the break or continue statements are in if or while loop, otherwise a semantic error will be thrown. For the Backend, we added 2 new instruction classes coresponding to both statements. The continue statement move the PC to the begining of the loop,which we have already set the label. For the break statement, it moves the PC to the end of the loop. So we set a new label at the end of a loop, then we can use the branch instruction to the label}


\subsection{Jas}
\subsubsection{Integer Literals of Different Bases} {The compiler now supports the use of octal, binary and hexadecimal integers. To indicate the use of these in the language, their corresponding representations must then be followed by an {\tt o}, {\tt b}, {\tt h} respectively. They can also be preceded by a {\tt +} or {\tt -} to indicate their sign. They are parsed and interpreted as normal integers during compilation}
\subsubsection{For Loops} {For loops can now be used in the WACC language. A for loop begins with a {\tt for} token followed by an identifier. This identifier represents the integer variable that is stored on the stack and is responsible for the interation of the loop. A for loop then consists of a {\tt from} token, an integer expression, a {\tt to} token, a second integer expression, a {\tt by} token, a third integer expression, a {\tt do} token, a statement and finally a {\tt done} token. The first expression represents the intial value of the iterating variable. The second expression represents the value at which the loop terminates once the iterating variable reaches it. The third expression represents the value by which the iterating variable is changed every iteration. The iterating variable can be accessed and modified using its identifier as standard in the language. The statement in the loop is executed once every iteration.}
\subsubsection{Dynamic Arrays} { The compiler also supports the use of dynamic arrays. A dynamic array can be assigned to a variable in the same way as an array literal. They are represented by the {\tt newarray} token followed by a type, an {\tt [} token, an integer expression and a {\tt ]} token. The value of the expression gives the size of the new array while the type tell us the type of its contents. Once called, an array of the given size is allocated on the heap with each element having an undefined value, requiring them to be initialised before use. The dynamic array can be accessed and modified as normal in the language.}
\subsubsection{Importing Dependencies} { The compiler can now import other files containing a mixture of functions and structs for use in the main program. These other files (called WAH files using the {\tt .wah} extension) can import WAH files themselves so they can also use structs and functions that are defined elsewhere. In order to import another file, an import statement is needed. This is indicated by an {\tt import} token followed by a file path. This path can also contain a wildcard allowing the user to easily import all the files in a given directory and its sub-directory. These import statements should typically be placed after the intial {\tt begin} token but before the statement in the main program as the contents of the dependencies is effectively copied into this exact location.

The process of importing a WAH file involves first error-checking any files that it also wishes to import. These files are then copied into a single line, replacing the import statement. The WAH file itself is then error checked and copied into the main program which is then compiled. Any syntax errors or semantics errors in the files causes the process to end and a suitable error message to be given. Note that this process does not have any effects on the main WACC file or any imported WAH files as all files are copied into a series of temporary files before compilation which are then deleted on completion.

To make sure that files are not imported twice, a record is kept of all of the absolute paths of the imported files. If a duplicate import is found (for example from a circular or diamond dependency) then it is still checked for any syntax or semantics errors but it does not copy that file. This means that any WAH file is only copied at most once into a WACC file.

If an import file has not been found, an error message will be displayed and the compilation will finish. }
\subsubsection{Constant Evaluation and Control Flow Analysis} { The compiler can now replace expressions consisting of literals with a literal equal to the result of the expression. This applies to both expressions and sub-expressions. The compiler is also able to use lazy evaluation on boolean expressions contain boolean literals. This process occurs automatically during compilation.

Similarly if the expression in an if statement is evaluated to be a boolean literal, the compiler simply converts the first statement in the if statement to assembly or the second statement depending on whether the boolean is {\tt true} or {\tt false}. The rest of the if statement can therefore be ignored. This process also happens automatically during compilation. }
\subsubsection{•}

\subsection{James}



\end{document}
